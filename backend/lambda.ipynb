{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc11348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.databases.management.longterm import LongTermManagement\n",
    "from package.databases.management.document import DocumentManagement\n",
    "from package.databases.session import get_session, Depends\n",
    "\n",
    "ltm = LongTermManagement()\n",
    "dm = DocumentManagement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc5c938",
   "metadata": {},
   "outputs": [],
   "source": [
    "longterm_id = '1ad51d70-b53c-4ffc-b7b5-d523ead048d6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a903dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Response Body: {\"errorMessage\": \"Unable to locate credentials\", \"errorType\": \"NoCredentialsError\", \"requestId\": \"a3416fc5-b82e-440d-b435-8e8dd9e30c73\", \"stackTrace\": [\"  File \\\"/var/task/lambda_function.py\\\", line 15, in lambda_handler\\n    response = model.run(system_prompt=system_prompt, messages=messages)\\n\", \"  File \\\"/var/task/package/llm/ollama.py\\\", line 67, in run\\n    response = model.converse(\\n\", \"  File \\\"/var/lang/lib/python3.13/site-packages/botocore/client.py\\\", line 598, in _api_call\\n    return self._make_api_call(operation_name, kwargs)\\n\", \"  File \\\"/var/lang/lib/python3.13/site-packages/botocore/context.py\\\", line 123, in wrapper\\n    return func(*args, **kwargs)\\n\", \"  File \\\"/var/lang/lib/python3.13/site-packages/botocore/client.py\\\", line 1043, in _make_api_call\\n    http, parsed_response = self._make_request(\\n\", \"  File \\\"/var/lang/lib/python3.13/site-packages/botocore/client.py\\\", line 1067, in _make_request\\n    return self._endpoint.make_request(operation_model, request_dict)\\n\", \"  File \\\"/var/lang/lib/python3.13/site-packages/botocore/endpoint.py\\\", line 119, in make_request\\n    return self._send_request(request_dict, operation_model)\\n\", \"  File \\\"/var/lang/lib/python3.13/site-packages/botocore/endpoint.py\\\", line 196, in _send_request\\n    request = self.create_request(request_dict, operation_model)\\n\", \"  File \\\"/var/lang/lib/python3.13/site-packages/botocore/endpoint.py\\\", line 132, in create_request\\n    self._event_emitter.emit(\\n\", \"  File \\\"/var/lang/lib/python3.13/site-packages/botocore/hooks.py\\\", line 412, in emit\\n    return self._emitter.emit(aliased_event_name, **kwargs)\\n\", \"  File \\\"/var/lang/lib/python3.13/site-packages/botocore/hooks.py\\\", line 256, in emit\\n    return self._emit(event_name, kwargs)\\n\", \"  File \\\"/var/lang/lib/python3.13/site-packages/botocore/hooks.py\\\", line 239, in _emit\\n    response = handler(**kwargs)\\n\", \"  File \\\"/var/lang/lib/python3.13/site-packages/botocore/signers.py\\\", line 106, in handler\\n    return self.sign(operation_name, request)\\n\", \"  File \\\"/var/lang/lib/python3.13/site-packages/botocore/signers.py\\\", line 198, in sign\\n    auth.add_auth(request)\\n\", \"  File \\\"/var/lang/lib/python3.13/site-packages/botocore/auth.py\\\", line 424, in add_auth\\n    raise NoCredentialsError()\\n\"]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://localhost:9000/2015-03-31/functions/function/invocations\"\n",
    "payload = {\n",
    "    # \"prompt\": \"Hi, how are you?\",\n",
    "    \"longterm_id\": longterm_id\n",
    "}  # your event payload\n",
    "\n",
    "response = requests.post(url, json=payload)\n",
    "\n",
    "print(\"Status Code:\", response.status_code)\n",
    "print(\"Response Body:\", response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b51f23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "def get_bedrock_client():\n",
    "    \"\"\"\n",
    "    Create a Bedrock client using the default AWS credentials and region.\n",
    "    \"\"\"\n",
    "    param = {\n",
    "        \"service_name\": \"bedrock-runtime\",\n",
    "        \"region_name\": \"us-west-2\",\n",
    "        # \"aws_access_key_id\": None,\n",
    "        # \"aws_secret_access_key\": None,\n",
    "        # \"aws_session_token\": None,\n",
    "    }    \n",
    "    return boto3.client(**param)\n",
    "\n",
    "def handler(event, context):\n",
    "    model_name = event.get(\"model_name\", \"us.meta.llama3-2-11b-instruct-v1:0\")\n",
    "    prompt = event.get(\"prompt\", \"Hello, Bedrock!\")\n",
    "    content = [{\"text\": prompt}]\n",
    "    model = get_bedrock_client()\n",
    "    response = model.converse(\n",
    "        modelId=model_name,\n",
    "        messages=[{\"role\": \"user\", \"content\": content}]\n",
    "    )\n",
    "    response = response['output']['message']['content'][0]['text']\n",
    "    return {\n",
    "        \"statusCode\": 200,\n",
    "        \"body\": \"Hello from Bedrock Postgres Lambda!\",\n",
    "        \"response\": response\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2465fd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'statusCode': 200,\n",
       " 'body': 'Hello from Bedrock Postgres Lambda!',\n",
       " 'response': \"Yabba dabba doo!  Hello there! I'm Bedrock's friendly AI, here to help and chat with you about all things prehistoric and beyond. What's on your mind? Want to talk about dinosaurs, the Flintstones, or something else entirely?\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler(event={}, context={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3ad83fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from broai.llm_management.ollama import BedrockOllamaChat\n",
    "\n",
    "model = BedrockOllamaChat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9391ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm doing well, thank you for asking. I'm here to help with any questions or information you might need. How can I assist you today?\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.run(\"You are a helpful assistant.\", messages=[model.UserMessage(\"Hi, how are you?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "709bbbb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "environ{'ALLUSERSPROFILE': 'C:\\\\ProgramData',\n",
       "        'APPDATA': 'C:\\\\Users\\\\Admin\\\\AppData\\\\Roaming',\n",
       "        'APPLICATIONINSIGHTS_CONFIGURATION_CONTENT': '{}',\n",
       "        'APPLICATION_INSIGHTS_NO_DIAGNOSTIC_CHANNEL': '1',\n",
       "        'APPLICATION_INSIGHTS_NO_STATSBEAT': 'true',\n",
       "        'CHROME_CRASHPAD_PIPE_NAME': '\\\\\\\\.\\\\pipe\\\\crashpad_19700_QTJFHIYPJLXMTWQM',\n",
       "        'COMMONPROGRAMFILES': 'C:\\\\Program Files\\\\Common Files',\n",
       "        'COMMONPROGRAMFILES(X86)': 'C:\\\\Program Files (x86)\\\\Common Files',\n",
       "        'COMMONPROGRAMW6432': 'C:\\\\Program Files\\\\Common Files',\n",
       "        'COMPUTERNAME': 'DESKTOP-EKNBFHV',\n",
       "        'COMSPEC': 'C:\\\\WINDOWS\\\\system32\\\\cmd.exe',\n",
       "        'DRIVERDATA': 'C:\\\\Windows\\\\System32\\\\Drivers\\\\DriverData',\n",
       "        'EFC_27848_1262719628': '1',\n",
       "        'EFC_27848_1592913036': '1',\n",
       "        'EFC_27848_2283032206': '1',\n",
       "        'EFC_27848_2775293581': '1',\n",
       "        'EFC_27848_3789132940': '1',\n",
       "        'ELECTRON_NO_ATTACH_CONSOLE': '1',\n",
       "        'ELECTRON_RUN_AS_NODE': '1',\n",
       "        'FPS_BROWSER_APP_PROFILE_STRING': 'Internet Explorer',\n",
       "        'FPS_BROWSER_USER_PROFILE_STRING': 'Default',\n",
       "        'HOMEDRIVE': 'C:',\n",
       "        'HOMEPATH': '\\\\Users\\\\Admin',\n",
       "        'JPY_INTERRUPT_EVENT': '2540',\n",
       "        'LOCALAPPDATA': 'C:\\\\Users\\\\Admin\\\\AppData\\\\Local',\n",
       "        'LOGONSERVER': '\\\\\\\\DESKTOP-EKNBFHV',\n",
       "        'NUMBER_OF_PROCESSORS': '32',\n",
       "        'ONEDRIVE': 'C:\\\\Users\\\\Admin\\\\OneDrive',\n",
       "        'ORIGINAL_XDG_CURRENT_DESKTOP': 'undefined',\n",
       "        'OS': 'Windows_NT',\n",
       "        'PATH': 'd:\\\\broai-arai\\\\backend\\\\.venv\\\\Scripts;D:\\\\broai-arai\\\\backend\\\\.venv\\\\Scripts;C:\\\\WINDOWS\\\\system32;C:\\\\WINDOWS;C:\\\\WINDOWS\\\\System32\\\\Wbem;C:\\\\WINDOWS\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\;C:\\\\WINDOWS\\\\System32\\\\OpenSSH\\\\;C:\\\\Program Files\\\\NVIDIA Corporation\\\\NVIDIA app\\\\NvDLISR;C:\\\\Program Files (x86)\\\\NVIDIA Corporation\\\\PhysX\\\\Common;C:\\\\Program Files\\\\Docker\\\\Docker\\\\resources\\\\bin;C:\\\\Program Files\\\\Git\\\\cmd;C:\\\\Program Files\\\\Amazon\\\\AWSCLIV2\\\\;C:\\\\Users\\\\Admin\\\\.local\\\\bin;C:\\\\Users\\\\Admin\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Users\\\\Admin\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\bin',\n",
       "        'PATHEXT': '.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC',\n",
       "        'PROCESSOR_ARCHITECTURE': 'AMD64',\n",
       "        'PROCESSOR_IDENTIFIER': 'Intel64 Family 6 Model 183 Stepping 1, GenuineIntel',\n",
       "        'PROCESSOR_LEVEL': '6',\n",
       "        'PROCESSOR_REVISION': 'b701',\n",
       "        'PROGRAMDATA': 'C:\\\\ProgramData',\n",
       "        'PROGRAMFILES': 'C:\\\\Program Files',\n",
       "        'PROGRAMFILES(X86)': 'C:\\\\Program Files (x86)',\n",
       "        'PROGRAMW6432': 'C:\\\\Program Files',\n",
       "        'PROMPT': '(backend) $P$G',\n",
       "        'PSMODULEPATH': 'C:\\\\Program Files\\\\WindowsPowerShell\\\\Modules;C:\\\\WINDOWS\\\\system32\\\\WindowsPowerShell\\\\v1.0\\\\Modules',\n",
       "        'PUBLIC': 'C:\\\\Users\\\\Public',\n",
       "        'PYDEVD_IPYTHON_COMPATIBLE_DEBUGGING': '1',\n",
       "        'PYTHONIOENCODING': 'utf-8',\n",
       "        'PYTHONUNBUFFERED': '1',\n",
       "        'PYTHON_FROZEN_MODULES': 'on',\n",
       "        'SESSIONNAME': 'Console',\n",
       "        'SYSTEMDRIVE': 'C:',\n",
       "        'SYSTEMROOT': 'C:\\\\WINDOWS',\n",
       "        'TEMP': 'C:\\\\Users\\\\Admin\\\\AppData\\\\Local\\\\Temp',\n",
       "        'TMP': 'C:\\\\Users\\\\Admin\\\\AppData\\\\Local\\\\Temp',\n",
       "        'USERDOMAIN': 'DESKTOP-EKNBFHV',\n",
       "        'USERDOMAIN_ROAMINGPROFILE': 'DESKTOP-EKNBFHV',\n",
       "        'USERNAME': 'Admin',\n",
       "        'USERPROFILE': 'C:\\\\Users\\\\Admin',\n",
       "        'VIRTUAL_ENV': 'D:\\\\broai-arai\\\\backend\\\\.venv',\n",
       "        'VIRTUAL_ENV_PROMPT': 'backend',\n",
       "        'VSCODE_CLI': '1',\n",
       "        'VSCODE_CODE_CACHE_PATH': 'C:\\\\Users\\\\Admin\\\\AppData\\\\Roaming\\\\Code\\\\CachedData\\\\2901c5ac6db8a986a5666c3af51ff804d05af0d4',\n",
       "        'VSCODE_CRASH_REPORTER_PROCESS_TYPE': 'extensionHost',\n",
       "        'VSCODE_CWD': 'D:\\\\broai-arai',\n",
       "        'VSCODE_ESM_ENTRYPOINT': 'vs/workbench/api/node/extensionHostProcess',\n",
       "        'VSCODE_HANDLES_UNCAUGHT_ERRORS': 'true',\n",
       "        'VSCODE_IPC_HOOK': '\\\\\\\\.\\\\pipe\\\\6dad4cc6-1.101.2-main-sock',\n",
       "        'VSCODE_L10N_BUNDLE_LOCATION': '',\n",
       "        'VSCODE_NLS_CONFIG': '{\"userLocale\":\"en-us\",\"osLocale\":\"en-us\",\"resolvedLanguage\":\"en\",\"defaultMessagesFile\":\"C:\\\\\\\\Users\\\\\\\\Admin\\\\\\\\AppData\\\\\\\\Local\\\\\\\\Programs\\\\\\\\Microsoft VS Code\\\\\\\\resources\\\\\\\\app\\\\\\\\out\\\\\\\\nls.messages.json\",\"locale\":\"en-us\",\"availableLanguages\":{}}',\n",
       "        'VSCODE_PID': '19700',\n",
       "        'WINDIR': 'C:\\\\WINDOWS',\n",
       "        '_OLD_VIRTUAL_PATH': 'C:\\\\WINDOWS\\\\system32;C:\\\\WINDOWS;C:\\\\WINDOWS\\\\System32\\\\Wbem;C:\\\\WINDOWS\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\;C:\\\\WINDOWS\\\\System32\\\\OpenSSH\\\\;C:\\\\Program Files\\\\NVIDIA Corporation\\\\NVIDIA app\\\\NvDLISR;C:\\\\Program Files (x86)\\\\NVIDIA Corporation\\\\PhysX\\\\Common;C:\\\\Program Files\\\\Docker\\\\Docker\\\\resources\\\\bin;C:\\\\Program Files\\\\Git\\\\cmd;C:\\\\Program Files\\\\Amazon\\\\AWSCLIV2\\\\;C:\\\\Users\\\\Admin\\\\.local\\\\bin;C:\\\\Users\\\\Admin\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Users\\\\Admin\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\bin',\n",
       "        '_OLD_VIRTUAL_PROMPT': '$P$G',\n",
       "        'PYDEVD_USE_FRAME_EVAL': 'NO',\n",
       "        'TERM': 'xterm-color',\n",
       "        'CLICOLOR': '1',\n",
       "        'FORCE_COLOR': '1',\n",
       "        'CLICOLOR_FORCE': '1',\n",
       "        'PAGER': 'cat',\n",
       "        'GIT_PAGER': 'cat',\n",
       "        'MPLBACKEND': 'module://matplotlib_inline.backend_inline'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9441f8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda Response: {'statusCode': 200, 'body': 'Hello from Bedrock Postgres Lambda!', 'response': 'The capital of France is Paris.'}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Create Lambda client\n",
    "lambda_client = boto3.client(\"lambda\", region_name=\"ap-southeast-1\")  # Change to your region\n",
    "\n",
    "# Set your function name and input event\n",
    "function_name = \"test-bedrock-postgres\"\n",
    "payload = {\n",
    "    \"prompt\": \"What is the capital of France?\",\n",
    "    # \"model_name\": \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "}\n",
    "\n",
    "# Invoke the function\n",
    "response = lambda_client.invoke(\n",
    "    FunctionName=function_name,\n",
    "    InvocationType=\"RequestResponse\",  # \"Event\" for async\n",
    "    Payload=json.dumps(payload),\n",
    ")\n",
    "\n",
    "# Read and parse the response\n",
    "response_payload = json.load(response[\"Payload\"])\n",
    "print(\"Lambda Response:\", response_payload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1b57291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda Response: {'statusCode': 200, 'body': 'done'}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Create Lambda client\n",
    "lambda_client = boto3.client(\"lambda\", region_name=\"ap-southeast-1\")  # Change to your region\n",
    "\n",
    "# Set your function name and input event\n",
    "function_name = \"test-bedrock-postgres-image\"\n",
    "payload = {\n",
    "    \"longterm_id\": longterm_id\n",
    "    # \"prompt\": \"What is the capital of Thailand?\",\n",
    "    # \"model_name\": \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "}\n",
    "\n",
    "# Invoke the function\n",
    "response = lambda_client.invoke(\n",
    "    FunctionName=function_name,\n",
    "    InvocationType=\"RequestResponse\",  # \"Event\" for async\n",
    "    Payload=json.dumps(payload),\n",
    ")\n",
    "\n",
    "# Read and parse the response\n",
    "response_payload = json.load(response[\"Payload\"])\n",
    "print(\"Lambda Response:\", response_payload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70eb5479",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltm = LongTermManagement()\n",
    "# longterm_id\n",
    "longterm = ltm.read_longterm(longterm_id, session=Depends(get_session))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "215bda98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Summary:**\n",
      "\n",
      "The provided context discusses the task of generating Wikipedia-like articles from scratch, focusing on the pre-writing stage, also known as research. The authors compare their work to existing literature on Wikipedia generation, highlighting the limitations of previous approaches. They emphasize the importance of generating full articles without prior outlines or references, which is a more challenging task.\n",
      "\n",
      "**Key Points:**\n",
      "\n",
      "1. The study focuses on generating Wikipedia-like articles from scratch, with an emphasis on the pre-writing stage (research).\n",
      "2. Existing literature on Wikipedia generation has limitations, such as generating only one paragraph, focusing on a specific domain, or relying on prior outlines or references.\n",
      "3. The authors' approach aims to generate full articles without prior outlines or references, which is a more challenging task.\n",
      "4. The study compares their work to prior benchmarks, including Balepur et al. (2023), Qian et al. (2023), Fan and Gardent (2022), Liu et al. (2018), and Sauper and Barzilay (2009).\n",
      "5. The authors' work is released on GitHub at https://github.com/stanford-oval/storm.\n",
      "\n",
      "2 FreshWiki\n",
      "\n",
      "We study generating Wikipedia-like articles from scratch, placing emphasis on the pre-writing stage (Rohman, 1965), which involves the demanding sub-tasks of gathering and curating relevant information ('research'). This models the human\n",
      "\n",
      "1 Our resources and code are released at https://github. com/stanford-oval/storm .\n",
      "\n",
      "Table 1: Comparison of different Wikipedia generation setups in existing literature. Generating one paragraph does not need an article outline.\n",
      "\n",
      "|                            | Domain   | Scope        | Given Outline?   | Given Refs?   |\n",
      "|----------------------------|----------|--------------|------------------|---------------|\n",
      "| Balepur et al. (2023)      | One      | One para.    | /                | Yes           |\n",
      "| Qian et al. (2023)         | All      | One para.    | /                | No            |\n",
      "| Fan and Gardent (2022)     | One      | Full article | Yes              | No            |\n",
      "| Liu et al. (2018)          | All      | One para.    | /                | Yes           |\n",
      "| Sauper and Barzilay (2009) | Two      | Full article | No               | No            |\n",
      "| Ours                       | All      | Full article | No               | No            |\n",
      "\n",
      "writing approach which has prompted some educators to view Wikipedia article writing as an educational exercise for academic training (Tardy, 2010).\n",
      "\n",
      "Table 1 compares our work against prior benchmarks for Wikipedia generation. Existing work has generally focused on evaluating the generation of shorter snippets ( e.g. , one paragraph), within a narrower scope ( e.g. , a specific domain or two), or when an explicit outline or reference documents are supplied. A\n"
     ]
    }
   ],
   "source": [
    "print(longterm.combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ae3199e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_id = 'fe8d0d2b-5e8f-49ae-922c-026eabedd8d3'\n",
    "# longterms = ltm.read_longterms_by_document(document_id=document_id, session=Depends(get_session))\n",
    "longterms = ltm.read_longterms_by_document(document_id=document_id, session=Depends(get_session))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "04535eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1ebafe7c-340c-41b0-869a-a43d9c0c51e4\n"
     ]
    }
   ],
   "source": [
    "print(longterms[2].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "06fa005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "longterm_ids = [longterm.id for longterm in longterms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8727125a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(longterm_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5db78e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution started!\n",
      "Execution ARN: arn:aws:states:ap-southeast-1:112557628841:execution:broai-arai-enrich-fleet:test-execution-cba979ed-6afe-4ac3-a80f-b1786317c3e0\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "# Replace this with your actual Step Function ARN\n",
    "# STATE_MACHINE_ARN = \"arn:aws:states:ap-southeast-1:123456789012:stateMachine:broai-arai-enrich-fleet\"\n",
    "STATE_MACHINE_ARN = \"arn:aws:states:ap-southeast-1:112557628841:stateMachine:broai-arai-enrich-fleet\"\n",
    "\n",
    "# Create a unique name for this execution\n",
    "execution_name = f\"test-execution-{uuid.uuid4()}\"\n",
    "\n",
    "# Input payload\n",
    "input_payload = {\n",
    "    # \"longterm_ids\": [\"id1\", \"id2\"],\n",
    "    \"longterm_ids\": longterm_ids[:]\n",
    "}\n",
    "\n",
    "# Create Step Functions client\n",
    "sfn = boto3.client(\"stepfunctions\", region_name=\"ap-southeast-1\")\n",
    "\n",
    "# Start execution\n",
    "response = sfn.start_execution(\n",
    "    stateMachineArn=STATE_MACHINE_ARN,\n",
    "    name=execution_name,\n",
    "    input=json.dumps(input_payload)\n",
    ")\n",
    "\n",
    "print(\"Execution started!\")\n",
    "print(\"Execution ARN:\", response[\"executionArn\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c0024663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution status: RUNNING\n",
      "Execution status: RUNNING\n",
      "Execution status: RUNNING\n",
      "Execution status: RUNNING\n",
      "Execution status: RUNNING\n",
      "Execution status: RUNNING\n",
      "Execution status: SUCCEEDED\n",
      "Execution output: {\"status\":\"success\",\"results\":[{\"Payload\":{\"processed\":\"a1b0fdca-848f-47d0-9eee-8f5d9f7d1c66\"}},{\"Payload\":{\"processed\":\"c92d372b-8586-40f5-b6f3-470e607401c2\"}},{\"Payload\":{\"processed\":\"1ebafe7c-340c-41b0-869a-a43d9c0c51e4\"}},{\"Payload\":{\"processed\":\"665713ac-08ee-4d8f-b0bd-b242c51d9348\"}},{\"Payload\":{\"processed\":\"fb138eca-e5e3-4857-bd08-ef313ec5dd4e\"}},{\"Payload\":{\"processed\":\"9c8c726b-c900-4507-a43a-59c53be5a47f\"}},{\"Payload\":{\"processed\":\"cb84687e-24d7-4981-aa40-3c79951636db\"}},{\"Payload\":{\"processed\":\"8859b95b-d13b-49e9-86a3-1402309cd82e\"}},{\"Payload\":{\"processed\":\"303f4cde-2980-44fc-9dbb-987e112556f9\"}},{\"Payload\":{\"processed\":\"8ef45766-f89d-4bec-bb5d-0700bd86f7d3\"}},{\"Payload\":{\"processed\":\"df24f975-43a1-4ad5-9796-3b32f1685aa2\"}},{\"Payload\":{\"processed\":\"9d468142-ae30-456e-9fbb-381060adf59d\"}},{\"Payload\":{\"processed\":\"aee5e24c-c076-4c24-9df4-d5ef792ae7bc\"}},{\"Payload\":{\"processed\":\"81897d52-c3eb-4569-b306-b488f748ffee\"}},{\"Payload\":{\"processed\":\"c05e50c4-13a8-4547-8946-8dff9bd94184\"}},{\"Payload\":{\"processed\":\"7bdb0408-9f5e-4fd2-ba4e-5665b721ee3f\"}},{\"Payload\":{\"processed\":\"5aa9a7f0-9711-47a6-af12-1e9ac3fb3723\"}},{\"Payload\":{\"processed\":\"607cfe4f-be26-4b99-a077-048fbb8059ae\"}},{\"Payload\":{\"processed\":\"941fcb20-9f99-4724-932d-fae0cecfb4b3\"}},{\"Payload\":{\"processed\":\"33bafea2-c405-48ee-aa56-24142d43d928\"}},{\"Payload\":{\"processed\":\"d899a386-174c-42fb-9a84-12512bd23214\"}},{\"Payload\":{\"processed\":\"f8a3ce6a-500d-417c-aa9c-d04a76723a91\"}},{\"Payload\":{\"processed\":\"999e64dd-5bf4-4793-9807-9c8104631274\"}},{\"Payload\":{\"processed\":\"8d643d95-b703-4bd5-ada7-59445bdc1ed6\"}},{\"Payload\":{\"processed\":\"235ed585-5f0b-4beb-84a2-13a09be27833\"}},{\"Payload\":{\"processed\":\"34c429a4-e65c-41d4-bc65-7d9246197e3a\"}},{\"Payload\":{\"processed\":\"9f41b23c-8eae-484c-a578-88fd66d58dca\"}},{\"Payload\":{\"processed\":\"7036b46b-608f-4069-a38b-013bb18828d1\"}},{\"Payload\":{\"processed\":\"053c768c-1fe6-4855-a125-0218b6a836b9\"}},{\"Payload\":{\"processed\":\"88e32c57-4b55-4190-a5f1-0e2482762391\"}},{\"Payload\":{\"processed\":\"924eec9d-d493-4fca-bcf2-f342cfbe81fd\"}},{\"Payload\":{\"processed\":\"1934d6c8-dc68-44c5-9e8c-2b24c6b2052c\"}},{\"Payload\":{\"processed\":\"8de80d32-dfda-4dca-a7bd-b600d5f108e3\"}},{\"Payload\":{\"processed\":\"a0f13682-38e6-4c64-ae03-82f3d6f39d2a\"}},{\"Payload\":{\"processed\":\"133c7e16-5243-41da-9ac5-3b39a4c71a91\"}},{\"Payload\":{\"processed\":\"30640f71-0632-448a-8dec-2430e374500c\"}},{\"Payload\":{\"processed\":\"7a2115ab-281e-47a1-913c-7f55332c4a37\"}},{\"Payload\":{\"processed\":\"70f18ab4-8e93-464e-a413-db07eb8c5cc0\"}},{\"Payload\":{\"processed\":\"6dd2c980-60a6-4e41-bf9e-9b141664b630\"}},{\"Payload\":{\"processed\":\"23ee5030-761c-46e2-8b90-254d57351af0\"}},{\"Payload\":{\"processed\":\"a6efc948-0dec-4fc5-8b51-997cf32afd94\"}},{\"Payload\":{\"processed\":\"7d3d493d-5b2a-45e6-8e23-ffb126106d45\"}},{\"Payload\":{\"processed\":\"ddab8f2e-726e-4862-990d-9b12f0195430\"}},{\"Payload\":{\"processed\":\"4e6a27bd-470b-425f-99d9-c09fe9fa0943\"}},{\"Payload\":{\"processed\":\"a071f60f-9a89-4ab4-944b-00a1d53d57ba\"}},{\"Payload\":{\"processed\":\"19a70d79-e169-4941-9bba-c055e120a2c7\"}},{\"Payload\":{\"processed\":\"eba3677f-68c3-4531-8136-8f2052bdf3ec\"}},{\"Payload\":{\"processed\":\"3394b386-daf8-41e9-aef3-94afa87e7b07\"}},{\"Payload\":{\"processed\":\"0d4267a9-e801-4ede-acfa-2698946fb27f\"}},{\"Payload\":{\"processed\":\"ef422785-656b-4946-b8b6-44a9e350d3c6\"}},{\"Payload\":{\"processed\":\"5b0e7a8b-83e1-4f3e-a2b6-c86efb4953da\"}},{\"Payload\":{\"processed\":\"bf9a88a5-6a29-4a34-b98a-049761ded161\"}},{\"Payload\":{\"processed\":\"0a02b3af-7435-4389-b802-98dbf2113c68\"}},{\"Payload\":{\"processed\":\"569bf7fe-bbe2-4006-be84-da4e31123133\"}},{\"Payload\":{\"processed\":\"be306257-c234-4856-a2c5-84448de093f7\"}},{\"Payload\":{\"processed\":\"a170dc39-defa-45af-b763-ea28b607892c\"}},{\"Payload\":{\"processed\":\"725b01b0-17db-436b-a193-ae763da0c115\"}},{\"Payload\":{\"processed\":\"bd65cde0-6192-455f-b513-e4d39a6bf88f\"}},{\"Payload\":{\"processed\":\"00d81d65-9555-4119-af50-f749dfe143fa\"}},{\"Payload\":{\"processed\":\"d01e6daf-106a-43ea-9c87-3dc5f2849bfa\"}},{\"Payload\":{\"processed\":\"4f33d725-6a71-4d51-9b99-f70d66834f4e\"}},{\"Payload\":{\"processed\":\"23b7c958-e85f-43c1-a23e-8623247d7aed\"}},{\"Payload\":{\"processed\":\"e5c5e2fc-bbac-482e-84fd-6b8cb0f3d6d0\"}},{\"Payload\":{\"processed\":\"1ef79b22-a94b-48e9-b5ca-c52c16a07df5\"}},{\"Payload\":{\"processed\":\"a8f4e2c2-c8b4-405d-8ba8-893865b9e948\"}},{\"Payload\":{\"processed\":\"d73649d9-d5fd-4cc6-8632-6a9385263475\"}},{\"Payload\":{\"processed\":\"9184391c-5702-4c8b-bebe-1f059f95e689\"}},{\"Payload\":{\"processed\":\"7ee67a73-58c1-4d77-b282-1aed2f5f7d3e\"}},{\"Payload\":{\"processed\":\"70658a2f-eaf3-426c-94b0-8d2c2969cc83\"}},{\"Payload\":{\"processed\":\"0da0c865-d511-4762-9986-81b70840c7bd\"}},{\"Payload\":{\"processed\":\"1b23cca6-f5ae-42d8-bc30-ff8d4606ca08\"}},{\"Payload\":{\"processed\":\"e82cd190-d7b9-443f-93a2-235107aefcb3\"}},{\"Payload\":{\"processed\":\"887cd07f-9f5c-4ed2-a5c8-e254a0175697\"}},{\"Payload\":{\"processed\":\"6beefc18-7d25-4479-a3aa-595296f6b2d3\"}},{\"Payload\":{\"processed\":\"ca23351f-e17a-4cb0-9fde-d1bad232e6b1\"}},{\"Payload\":{\"processed\":\"deb05bfc-99e8-43c1-99fc-acd1b51b3353\"}},{\"Payload\":{\"processed\":\"57e0d8c9-0385-4026-8711-39340a29dc89\"}},{\"Payload\":{\"processed\":\"d0d36614-beb7-48d0-82da-f72c89fa99c0\"}},{\"Payload\":{\"processed\":\"34dc616a-fc90-4f47-9ecb-8ac40d582b34\"}},{\"Payload\":{\"processed\":\"abba2c7f-473c-4785-855e-54c988bf9498\"}},{\"Payload\":{\"processed\":\"38304fab-5632-4f10-b087-283519056cb1\"}},{\"Payload\":{\"processed\":\"63d2521a-2469-43ab-bae7-bb3da81d8625\"}},{\"Payload\":{\"processed\":\"b8ccbcb9-58a6-40d2-b118-8707cf09b246\"}},{\"Payload\":{\"processed\":\"4960e822-e7db-43c9-ab91-9641f46b4c76\"}},{\"Payload\":{\"processed\":\"5f912329-67d5-4d51-9485-c6a7c46a522b\"}},{\"Payload\":{\"processed\":\"eef2011d-7cc0-4fdc-b4be-83aceac5ec71\"}},{\"Payload\":{\"processed\":\"3766ac91-50c2-4ce7-82f4-4755ea54c818\"}}]}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "execution_arn = response[\"executionArn\"]\n",
    "\n",
    "while True:\n",
    "    desc = sfn.describe_execution(executionArn=execution_arn)\n",
    "    status = desc[\"status\"]\n",
    "    print(f\"Execution status: {status}\")\n",
    "    if status in (\"SUCCEEDED\", \"FAILED\", \"TIMED_OUT\", \"ABORTED\"):\n",
    "        break\n",
    "    time.sleep(2)\n",
    "\n",
    "if status == \"SUCCEEDED\":\n",
    "    output = desc.get(\"output\")\n",
    "    print(\"Execution output:\", output)\n",
    "else:\n",
    "    print(f\"Execution ended with status: {status}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7bbfca5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Payload': {'processed': 'a1b0fdca-848f-47d0-9eee-8f5d9f7d1c66'}},\n",
       " {'Payload': {'processed': 'c92d372b-8586-40f5-b6f3-470e607401c2'}},\n",
       " {'Payload': {'processed': '1ebafe7c-340c-41b0-869a-a43d9c0c51e4'}},\n",
       " {'Payload': {'processed': '665713ac-08ee-4d8f-b0bd-b242c51d9348'}},\n",
       " {'Payload': {'processed': 'fb138eca-e5e3-4857-bd08-ef313ec5dd4e'}},\n",
       " {'Payload': {'processed': '9c8c726b-c900-4507-a43a-59c53be5a47f'}},\n",
       " {'Payload': {'processed': 'cb84687e-24d7-4981-aa40-3c79951636db'}},\n",
       " {'Payload': {'processed': '8859b95b-d13b-49e9-86a3-1402309cd82e'}},\n",
       " {'Payload': {'processed': '303f4cde-2980-44fc-9dbb-987e112556f9'}},\n",
       " {'Payload': {'processed': '8ef45766-f89d-4bec-bb5d-0700bd86f7d3'}},\n",
       " {'Payload': {'processed': 'df24f975-43a1-4ad5-9796-3b32f1685aa2'}},\n",
       " {'Payload': {'processed': '9d468142-ae30-456e-9fbb-381060adf59d'}},\n",
       " {'Payload': {'processed': 'aee5e24c-c076-4c24-9df4-d5ef792ae7bc'}},\n",
       " {'Payload': {'processed': '81897d52-c3eb-4569-b306-b488f748ffee'}},\n",
       " {'Payload': {'processed': 'c05e50c4-13a8-4547-8946-8dff9bd94184'}},\n",
       " {'Payload': {'processed': '7bdb0408-9f5e-4fd2-ba4e-5665b721ee3f'}},\n",
       " {'Payload': {'processed': '5aa9a7f0-9711-47a6-af12-1e9ac3fb3723'}},\n",
       " {'Payload': {'processed': '607cfe4f-be26-4b99-a077-048fbb8059ae'}},\n",
       " {'Payload': {'processed': '941fcb20-9f99-4724-932d-fae0cecfb4b3'}},\n",
       " {'Payload': {'processed': '33bafea2-c405-48ee-aa56-24142d43d928'}},\n",
       " {'Payload': {'processed': 'd899a386-174c-42fb-9a84-12512bd23214'}},\n",
       " {'Payload': {'processed': 'f8a3ce6a-500d-417c-aa9c-d04a76723a91'}},\n",
       " {'Payload': {'processed': '999e64dd-5bf4-4793-9807-9c8104631274'}},\n",
       " {'Payload': {'processed': '8d643d95-b703-4bd5-ada7-59445bdc1ed6'}},\n",
       " {'Payload': {'processed': '235ed585-5f0b-4beb-84a2-13a09be27833'}},\n",
       " {'Payload': {'processed': '34c429a4-e65c-41d4-bc65-7d9246197e3a'}},\n",
       " {'Payload': {'processed': '9f41b23c-8eae-484c-a578-88fd66d58dca'}},\n",
       " {'Payload': {'processed': '7036b46b-608f-4069-a38b-013bb18828d1'}},\n",
       " {'Payload': {'processed': '053c768c-1fe6-4855-a125-0218b6a836b9'}},\n",
       " {'Payload': {'processed': '88e32c57-4b55-4190-a5f1-0e2482762391'}},\n",
       " {'Payload': {'processed': '924eec9d-d493-4fca-bcf2-f342cfbe81fd'}},\n",
       " {'Payload': {'processed': '1934d6c8-dc68-44c5-9e8c-2b24c6b2052c'}},\n",
       " {'Payload': {'processed': '8de80d32-dfda-4dca-a7bd-b600d5f108e3'}},\n",
       " {'Payload': {'processed': 'a0f13682-38e6-4c64-ae03-82f3d6f39d2a'}},\n",
       " {'Payload': {'processed': '133c7e16-5243-41da-9ac5-3b39a4c71a91'}},\n",
       " {'Payload': {'processed': '30640f71-0632-448a-8dec-2430e374500c'}},\n",
       " {'Payload': {'processed': '7a2115ab-281e-47a1-913c-7f55332c4a37'}},\n",
       " {'Payload': {'processed': '70f18ab4-8e93-464e-a413-db07eb8c5cc0'}},\n",
       " {'Payload': {'processed': '6dd2c980-60a6-4e41-bf9e-9b141664b630'}},\n",
       " {'Payload': {'processed': '23ee5030-761c-46e2-8b90-254d57351af0'}},\n",
       " {'Payload': {'processed': 'a6efc948-0dec-4fc5-8b51-997cf32afd94'}},\n",
       " {'Payload': {'processed': '7d3d493d-5b2a-45e6-8e23-ffb126106d45'}},\n",
       " {'Payload': {'processed': 'ddab8f2e-726e-4862-990d-9b12f0195430'}},\n",
       " {'Payload': {'processed': '4e6a27bd-470b-425f-99d9-c09fe9fa0943'}},\n",
       " {'Payload': {'processed': 'a071f60f-9a89-4ab4-944b-00a1d53d57ba'}},\n",
       " {'Payload': {'processed': '19a70d79-e169-4941-9bba-c055e120a2c7'}},\n",
       " {'Payload': {'processed': 'eba3677f-68c3-4531-8136-8f2052bdf3ec'}},\n",
       " {'Payload': {'processed': '3394b386-daf8-41e9-aef3-94afa87e7b07'}},\n",
       " {'Payload': {'processed': '0d4267a9-e801-4ede-acfa-2698946fb27f'}},\n",
       " {'Payload': {'processed': 'ef422785-656b-4946-b8b6-44a9e350d3c6'}},\n",
       " {'Payload': {'processed': '5b0e7a8b-83e1-4f3e-a2b6-c86efb4953da'}},\n",
       " {'Payload': {'processed': 'bf9a88a5-6a29-4a34-b98a-049761ded161'}},\n",
       " {'Payload': {'processed': '0a02b3af-7435-4389-b802-98dbf2113c68'}},\n",
       " {'Payload': {'processed': '569bf7fe-bbe2-4006-be84-da4e31123133'}},\n",
       " {'Payload': {'processed': 'be306257-c234-4856-a2c5-84448de093f7'}},\n",
       " {'Payload': {'processed': 'a170dc39-defa-45af-b763-ea28b607892c'}},\n",
       " {'Payload': {'processed': '725b01b0-17db-436b-a193-ae763da0c115'}},\n",
       " {'Payload': {'processed': 'bd65cde0-6192-455f-b513-e4d39a6bf88f'}},\n",
       " {'Payload': {'processed': '00d81d65-9555-4119-af50-f749dfe143fa'}},\n",
       " {'Payload': {'processed': 'd01e6daf-106a-43ea-9c87-3dc5f2849bfa'}},\n",
       " {'Payload': {'processed': '4f33d725-6a71-4d51-9b99-f70d66834f4e'}},\n",
       " {'Payload': {'processed': '23b7c958-e85f-43c1-a23e-8623247d7aed'}},\n",
       " {'Payload': {'processed': 'e5c5e2fc-bbac-482e-84fd-6b8cb0f3d6d0'}},\n",
       " {'Payload': {'processed': '1ef79b22-a94b-48e9-b5ca-c52c16a07df5'}},\n",
       " {'Payload': {'processed': 'a8f4e2c2-c8b4-405d-8ba8-893865b9e948'}},\n",
       " {'Payload': {'processed': 'd73649d9-d5fd-4cc6-8632-6a9385263475'}},\n",
       " {'Payload': {'processed': '9184391c-5702-4c8b-bebe-1f059f95e689'}},\n",
       " {'Payload': {'processed': '7ee67a73-58c1-4d77-b282-1aed2f5f7d3e'}},\n",
       " {'Payload': {'processed': '70658a2f-eaf3-426c-94b0-8d2c2969cc83'}},\n",
       " {'Payload': {'processed': '0da0c865-d511-4762-9986-81b70840c7bd'}},\n",
       " {'Payload': {'processed': '1b23cca6-f5ae-42d8-bc30-ff8d4606ca08'}},\n",
       " {'Payload': {'processed': 'e82cd190-d7b9-443f-93a2-235107aefcb3'}},\n",
       " {'Payload': {'processed': '887cd07f-9f5c-4ed2-a5c8-e254a0175697'}},\n",
       " {'Payload': {'processed': '6beefc18-7d25-4479-a3aa-595296f6b2d3'}},\n",
       " {'Payload': {'processed': 'ca23351f-e17a-4cb0-9fde-d1bad232e6b1'}},\n",
       " {'Payload': {'processed': 'deb05bfc-99e8-43c1-99fc-acd1b51b3353'}},\n",
       " {'Payload': {'processed': '57e0d8c9-0385-4026-8711-39340a29dc89'}},\n",
       " {'Payload': {'processed': 'd0d36614-beb7-48d0-82da-f72c89fa99c0'}},\n",
       " {'Payload': {'processed': '34dc616a-fc90-4f47-9ecb-8ac40d582b34'}},\n",
       " {'Payload': {'processed': 'abba2c7f-473c-4785-855e-54c988bf9498'}},\n",
       " {'Payload': {'processed': '38304fab-5632-4f10-b087-283519056cb1'}},\n",
       " {'Payload': {'processed': '63d2521a-2469-43ab-bae7-bb3da81d8625'}},\n",
       " {'Payload': {'processed': 'b8ccbcb9-58a6-40d2-b118-8707cf09b246'}},\n",
       " {'Payload': {'processed': '4960e822-e7db-43c9-ab91-9641f46b4c76'}},\n",
       " {'Payload': {'processed': '5f912329-67d5-4d51-9485-c6a7c46a522b'}},\n",
       " {'Payload': {'processed': 'eef2011d-7cc0-4fdc-b4be-83aceac5ec71'}},\n",
       " {'Payload': {'processed': '3766ac91-50c2-4ce7-82f4-4755ea54c818'}}]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "payloads = json.loads(output)['results']\n",
    "payloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ce9a8285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Summary:**\n",
      "\n",
      "The context discusses the challenges of using large language models (LLMs) to write grounded, long-form articles, such as full-length Wikipedia pages. Current approaches to generating Wikipedia articles often bypass the pre-writing stage, which involves thorough research and planning. However, this stage is crucial for producing high-quality articles. The authors propose a new approach, called STORM (Synthesis of Topic-based Research and Multi-level Outlining), which aims to automate the pre-writing stage by leveraging external sources and human learning theories. STORM involves two tasks: generating an outline and collecting reference documents, and then using the outline and references to produce the full-length article.\n",
      "\n",
      "**Key Points:**\n",
      "\n",
      "1. Current LLMs struggle to write grounded, long-form articles due to limitations in their pre-writing stage.\n",
      "2. The pre-writing stage involves thorough research and planning, which is essential for producing high-quality articles.\n",
      "3. Current approaches to generating Wikipedia articles often bypass the pre-writing stage, relying on direct prompting or retrieval-augmented generation.\n",
      "4. The STORM paradigm proposes a new approach to automating the pre-writing stage by leveraging external sources and human learning theories.\n",
      "5. STORM involves two tasks: generating an outline and collecting reference documents, and then using the outline and references to produce the full-length article.\n",
      "6. The authors highlight the importance of asking effective questions in information acquisition, which is a key aspect of the STORM paradigm.\n",
      "\n",
      "1 Introduction\n",
      "\n",
      "Large language models (LLMs) have demonstrated impressive writing capabilities (Yang et al., 2023; Pavlik, 2023; Wenzlaff and Spaeth, 2022; Fitria, 2023), but it is unclear how we can use them to write grounded, long-form articles, like full-length Wikipedia pages. Such expository writing, which seeks to inform the reader on a topic in an organized manner (Weaver III and Kintsch, 1991; Balepur et al., 2023), requires thorough research and planning in the pre-writing stage (Rohman,\n",
      "\n",
      "<!-- image -->\n",
      "\n",
      "Role1\n",
      "\n",
      "Figure 1: We explore writing Wikipedia-like articles from scratch, which demands a pre-writing stage before producing the article. In this stage, simpler approaches like Direct Prompting have limited planning capacity. In contrast, STORM researches the topic via perspectiveguided question asking in simulated conversations.\n",
      "\n",
      "1965), even before the actual writing process can start. However, prior work on generating Wikipedia articles (Banerjee and Mitra, 2015; Minguill√≥n et al., 2017; Liu et al., 2018; Fan and Gardent, 2022) has generally bypassed the pre-writing stage: for instance, Liu et al. (2018) presume reference documents are provided in advance, while Fan and Gardent (2022) assume an article outline is available and focus on expanding each section. These assumptions do not hold in general, as collecting references and crafting outlines demand advanced information literacy skills (Doyle, 1994) to iden- tify, evaluate, and organize external sources - a task that is challenging even for experienced writers. Automating this process can facilitate individuals in initiating in-depth learning about a topic and greatly reduce the expensive expert hours necessary for their expository writing.\n",
      "\n",
      "We explore these challenges by focusing on how to generate Wikipedia-like articles from scratch . We decompose this problem into two tasks. The first is to conduct research to generate an outline, i.e. , a list of multi-level sections, and collect a set of reference documents. The second uses the outline and the references to produce the full-length article. Such a task decomposition mirrors the human writing process which usually includes phases of pre-writing, drafting, and revising (Rohman, 1965; Munoz-Luna, 2015).\n",
      "\n",
      "As pre-trained language models inherently possess a wealth of knowledge, a direct approach is to rely on their parametric knowledge for generating outlines or even entire articles ( Direct Gen ). However, this approach is limited by a lack of details and hallucinations (Xu et al., 2023), particularly in addressing long-tail topics (Kandpal et al., 2023). This underscores the importance of leveraging external sources, and current strategies often involve retrieval-augmented generation ( RAG ), which circles back to the problem of researching the topic in the pre-writing stage, as much information cannot be surfaced through simple topic searches.\n",
      "\n",
      "Human learning theories (Tawfik et al., 2020; Booth et al., 2003) highlight asking effective questions in information acquisition. Although instruction-tuned models (Ouyang et al., 2022) can be prompted directly to generate questions, we find that they typically produce basic 'What', 'When', and 'Where' questions (Figure 1 (A)) which often only address surface-level facts about the topic. To endow LLMs with the capacity to conduct better research, we propose the STORM paradigm for the S ynthesis\n"
     ]
    }
   ],
   "source": [
    "longterm_id = payloads[-1]['Payload']['processed']\n",
    "print(ltm.read_longterm(longterm_id, session=Depends(get_session)).combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae52ca8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
